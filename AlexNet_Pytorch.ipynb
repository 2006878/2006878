{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDkf676p9BZeaDXslrmDsw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP-gwNHvZcRy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "net = nn.Sequential(\n",
        "    # Aqui, usamos uma janela maior de 11 x 11 para capturar objetos. Ao mesmo tempo,\n",
        "    # usamos um passo de 4 para reduzir significativamente a altura e a largura\n",
        "    # da saída. Aqui, o número de canais de saída\n",
        "    # é muito maior do que no LeNet\n",
        "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    # Torne a janela de convolução menor, defina o preenchimento para 2\n",
        "    # para altura e largura consistentes na entrada e saída,\n",
        "    # e aumente o número de canais de saída\n",
        "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    # Use três camadas convolucionais sucessivas e uma janela de convolução menor.\n",
        "    # Exceto para a camada convolucional final, o número de canais de saída\n",
        "    # é aumentado ainda mais. Camadas de pooling não são usadas para reduzir\n",
        "    # a altura e largura de entrada após as duas primeiras camadas convolucionais\n",
        "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    nn.Flatten(),\n",
        "    # Aqui, o número de saídas da camada totalmente conectada é várias\n",
        "    # vezes maior do que no LeNet.\n",
        "    # Use a camada de eliminação para mitigar overfitting\n",
        "    nn.Linear(6400, 4096), nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(4096, 4096), nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    # Camada de saída. Como estamos usando o Fashion-MNIST,\n",
        "    # o número de classes é 10, em vez de 1000 como no papel\n",
        "    nn.Linear(4096, 10))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(1, 1, 224, 224)\n",
        "for layer in net:\n",
        "    X=layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
      ],
      "metadata": {
        "id": "O4MvBuA6bbwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)"
      ],
      "metadata": {
        "id": "UtNPGOoJbd8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs = 0.01, 10\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "J_aOnxLvbjt2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}